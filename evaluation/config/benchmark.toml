# Benchmark Configuration for Basic RAG Experiment
# Contains experiment-specific configurations that override global defaults

# Strategy
# Basic Paragraph Chunking using "\n\n" as separator
# Basic Similarity Retrieval using OpenAI embeddings

[strategies]
# Strategy selection for the benchmark experiment
[strategies.chunking]
# Chunking strategy to use: "basic_paragraph"
strategy = "basic_paragraph"

[strategies.retrieval]
# Retrieval strategy to use: "basic_similarity"
strategy = "basic_similarity"

[ingestion]
# Maximum tokens per chunk
max_tokens = 1000
# API delay between requests (seconds)
api_delay = 0.1


[embeddings]
# Internal configuration (not passed to OpenAI API)
batch_size = 100  # For our internal batching logic
delay_seconds = 0.1  # Rate limiting delay

[embeddings.openai]
# OpenAI API parameters (passed directly to embeddings.create)
# Supabase does not support embedding > 2000 dims, making text-embedding-3-large unusable
model = "text-embedding-3-small"
dimensions = 1536


[evaluation]
# Default k values for precision@k evaluation
k_values = [1, 3, 5]
# Metrics to evaluate
metrics = ["precision", "recall", "mrr", "ndcg"]
# Rouge threshold (f1-measure) for retrieval
rouge_threshold = 0.7
# Whether to save detailed individual metric results to separate JSON files
save_individual_results = false